---
title: "glmnet_siq"
author: "Jackie"
date: "5/24/2020"
output: html_notebook
---

##Regularized regression

We have observations on n units of a DV and p predictors, where p >> n. 

Choosing the value of Î» under the L1-norm and extracting coefficients based on that penalty value.

```{r, echo=FALSE}
library(glmnet)
library(glmpath)
library(lars)
library(tidyverse)
library(dynutils)
library(readxl)
library(haven)
library(naniar)
library(pscl)
library(MASS)
library(stringr)
library(sjPlot)
library(directlabels)
library(caret)

graph_net_fp <- "~/Box/siq_graph.csv"

graph_net <- read_csv(graph_net_fp)
```

```{r}
options(scipen=999) 
z_score <- function(x) {
diff_mu <- x - mean(x, na.rm = T)
sd <- sd(x, na.rm = T)
diff_mu / sd
}
```

## de-selecting variables
```{r}
graph_net_select <- graph_net %>%
  dplyr::select(-c(siq_total.T3, age_s1.T3, tan_avg.T3, cdi_TOTAL.T3, ELS_ID))
```

interval_s2t1_s1t3, Parent_Education.T1, KSADS_Child_Race_by_P.T1, sss_t1, age_s1.T1, Tanner_Average.T1, cdi_TOTAL.T1

```{r}
# tranforming cdi
library(dlookr)
cdi_z <- graph_net_select %>% 
  mutate(cdi_minmax = transform(graph_net_select$cdi_TOTAL.T1, method = "minmax")) %>%
  dplyr::select(cdi_minmax) %>% 
  boxplot()

cdi_log = transform(graph_net_select$cdi_TOTAL.T1, method = "log+1") # can't do log of 0, so doing log + 1
summary(cdi_log)
plot(cdi_log)

graph_net_select <- graph_net_select %>%
  mutate(
    cdi_TOTAL.T1_log = transform(graph_net_select$cdi_TOTAL.T1, method = "log+1")
  ) %>%
  dplyr::select(-cdi_TOTAL.T1)

```

```{r}

graph_net_stand <- graph_net_select %>%
  mutate(KSADS_Child_Race_by_P.T1 = factor(KSADS_Child_Race_by_P.T1),
         KSADS_Child_Race_by_P.T1_bin = ifelse(KSADS_Child_Race_by_P.T1 == "1", "1", "0"),
         sex_child = factor(sex_child)) %>%
  dplyr::select(-KSADS_Child_Race_by_P.T1) %>%
  mutate_at(vars(-siq_total_log, -KSADS_Child_Race_by_P.T1_bin, -sex_child), z_score) %>%
  dplyr::select(siq_total_log, cdi_TOTAL.T1_log, KSADS_Child_Race_by_P.T1_bin, everything())

graph_net_stand_siq <- graph_net_stand %>%
  mutate(siq_total_log_z = scale(siq_total_log, center = TRUE, scale = TRUE)) %>%
  dplyr::select(-siq_total_log, -KSADS_Child_Race_by_P.T1_bin, -sex_child) %>%
  dplyr::select(siq_total_log_z, everything())

predictors_scaled <- as.matrix(graph_net_stand_siq[2:1259])

siq_scaled <-graph_net_stand_siq$siq_total_log_z

```

## to get sense of coefficient path
```{r}
lasso <- glmnet(predictors_scaled, siq_scaled, family = "gaussian", alpha = 1)
plot(lasso, xvar = "dev", label = TRUE)
```



# cross-val to pick lambda
```{r}
# for loop and summary from Lucy King
set.seed(1234)
lambdaMins <- c()
for (i in 1:1000) {
fit_cv <- cv.glmnet(predictors_scaled, siq_scaled, alpha = 1, family = "gaussian")
lambdaMins <- cbind(lambdaMins, fit_cv$lambda.min)
}

plot(fit_cv, sign.lambda = 1)

# gathering lambda.ins
lambdaMins <- as_tibble(lambdaMins)
lambdaMins_long <-
lambdaMins %>%
gather(run, lambdaMin, V1:V1000)

# summarizing results
lambdaMins_long %>%
ggplot(mapping = aes(x = "", y = lambdaMin)) +
geom_boxplot() +
coord_flip() +
labs(
x = ""
)
lambdas_summary <-
lambdaMins_long %>%
summarise(
min_mean = mean(lambdaMin),
min_median = median(lambdaMin),
min_sd = sd(lambdaMin)
)
options(max.print = 1260)
coefs_cv <- coef(fit_cv, s = lambdas_summary$min_median) 

# comuting RSquared value
X <- model.matrix(siq_total_log_z ~ ., data = graph_net_stand_siq)
# predict
y_hat <- matrix(X, ncol = ncol(X)) %*% matrix(coefs_cv, nrow(coefs_cv))
# R-Squared
r_sq <- 1 - (sum((y_hat[, 1] - siq_scaled)^2) / sum((siq_scaled - mean(siq_scaled))^2))
#  0.3340407
```


just checking zero-order correlations to see if lasso results make sense
```{r}
# 1. 
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$SN_R_226.wm_z)
# r = 0.366, p = 0.0001669 

# 2.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$PrG_L_63.deg)
# r = -0.386, p = 0.0000671 

# 3.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$FuG_L_105.deg)
# r = 0.350, p = 0.0003392 
# 4.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$sumsev_type_t1)
# r = 0.292, p = 0.003023 
# 5.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$cTtha_R_250.eig_cent)
# r = 0.299,p = 0.002351 
# 6.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$PrG_L_63.eig_cent)
# r = -0.350, p = 0.0003371 

# 7.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$CG_L_183.pc)
# r = -0.228, p = 0.02204 
# 8.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$IFG_R_34.deg)
# r = -0.268, p = 0.006788 

# 9.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$Amyg_R_212.eff_loc )
#r = 0.262, p = 0.008097 

# 10.
cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$STG_R_72.pc )
#r = 0.2016191, p = 0.04319 

cor.test(graph_net_stand_siq$siq_total_log_z, graph_net_stand_siq$dCA_R_234.eig_cent)
#r = 0.2290662 , p = 0.02121 
```


## if i want to split into test and training sets
From: http://chenyuan.date/2017/11/Penalized-Regression-Ridge-Lasso-Elastic-Net/

```{r}

# # Split the data into training and test set

training.samples <- graph_net_stand_siq$siq_total_log_z %>%    # response variable
                    createDataPartition(p = 0.8, list = FALSE)

train.data  <- graph_net_stand_siq[training.samples, ]
test.data <- graph_net_stand_siq[-training.samples, ]
```

 After creating the model matrix, we remove the intercept component at index = 1.
```{r}
# Predictor variables
x_lasso_tt <- model.matrix(siq_total_log_z ~., train.data)[,-1]  

# Response variable
y_lasso_tt <- train.data$siq_total_log_z
```

### test data
```{r}
x.test <- model.matrix(siq_total_log_z ~., test.data)[,-1]
y.test <- test.data$siq_total_log_z
```

# Make predictions on the test data
```{r}
# Rebuilding the model with best lamda value identified
lasso_best <- glmnet(x_lasso_tt, y_lasso_tt, alpha = 1, lambda = lambdas_summary$min_median)
pred <- predict(lasso_best, s = lambdas_summary$min_median, newx = x.test)
```


```{r}
final <- cbind(y.test, pred)
# Checking the first six obs
head(final)

coef(lasso_best)

# R-Squared
r_sq_test <- 1 - (sum((pred[, 1] - y.test)^2) / sum((y.test - mean(y.test))^2))
# 0.09096923

# actual <- test.data$siq_total_log_z
# preds <- pred
# rss <- sum((preds - actual) ^ 2)
# tss <- sum((actual - mean(actual)) ^ 2)
# rsq <- 1 - rss/tss

```


# Plotting

```{r}
lasso_results_fp <- "~/Box/tbl5toPlot.xlsx"

lasso_results <- read_excel(lasso_results_fp)
```

```{r}
lasso_results <- lasso_results %>%
  ggplot(
    aes(
      x = reorder(Variable, sibetavalue),
      y = sibetavalue,
      fill = Lobe
    )
  ) + 
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Variable", y = "SI Beta Value") +
  ggtitle("Predictors of Suicidal Ideation") +
  theme_blank() +
  scale_fill_brewer(palette="Set2")

ggsave("lasso_results.jpg", lasso_results, width = 7, height = 5)
```

